# Blood Test Report Analyser

This project is a powerful tool for analyzing blood test reports from PDF files. It uses a team of AI agents to provide a comprehensive analysis, including a medical summary, nutrition advice, and an exercise plan.

### Architecture Diagram

The following diagram illustrates the high-level architecture of the system, showing how the UI, task queue, background worker, and database interact.

![Architecture Diagram](/vwo-assignment/outputs/Architecture.png)



## Features

-   **AI-Powered Analysis**: Utilizes a team of AI agents (Doctor, Verifier, Nutritionist, and Exercise Specialist) to provide a holistic health analysis.
-   **Advanced PDF Extraction**: Tested multiple PDF extraction libraries and found `camelot` to be the most effective for table-based data extraction from blood reports.
-   **Efficient RAG Pipeline**: Implemented document chunking and a `ChromaDB` vector store for efficient retrieval-augmented generation.
-   **LLM Flexibility**: Tested with the free `Gemini` API, showcasing adaptability to different language models.
-   **Asynchronous Task Processing**: Uses a Celery worker with a Redis queue to handle long-running analysis tasks without blocking the UI.
-   **Database Integration**: Stores all analysis requests and results in an SQLite database for persistence and retrieval.
-   **Chat Interface**: Offers an interactive chat-based interface built with [Chainlit](https://chainlit.io/) for a user-friendly experience.
-   **REST API**: Provides a REST API built with [FastAPI](https://fastapi.tiangolo.com/) for programmatic access and integration.
-   **Comprehensive Reports**: Generates detailed reports covering medical summaries, nutritional recommendations, and personalized exercise plans.



## Debugging Challenge

This project was initially presented as a debugging challenge. The codebase contained several bugs, ranging from simple dependency issues to more complex logical and architectural flaws. The challenge was to identify and fix these bugs to make the application fully functional.

### Bugs Identified and Fixed

The following bugs were identified and fixed during the debugging process:

-   **Configuration and Dependency Issues**:
    -   Missing `uvicorn` dependency in `requirements.txt`.
    -   Incorrect `Agent` and `SerperDevTool` imports in `agents.py`.
    -   Undefined `PDFLoader` in `tools.py` due to a missing import.

-   **Runtime Errors**:
    -   `NameError` due to an uninitialized `llm` variable in `agents.py`.
    -   `TypeError` because `read_data_tool` was not declared as a static method.
    -   `ValidationError` from passing a function instead of a `BaseTool` instance to an agent.
    -   `AttributeError` from incorrectly accessing uploaded file content in `app.py`.

-   **Logical and Functional Bugs**:
    -   Hardcoded file path in `read_data_tool`, causing the application to ignore user-uploaded files.
    -   All tasks were assigned to a single agent, leaving other specialist agents unused.
    -   Only one task was added to the crew in `main.py`, resulting in an incomplete report.
    -   Specialist agents were not provided with the necessary tools to perform their tasks.
    -   `NutritionTool` and `ExerciseTool` had placeholder logic and were not implemented.

-   **Harmful AI Behavior**:
    -   The initial prompts and backstories for the agents were designed to generate satirical and harmful advice. These have been corrected to provide helpful and accurate information.

-   **UI and Tool Enhancements**:
    -   A new interactive frontend was created using Chainlit, and the file handling was fixed to ensure a smooth user experience.
    -   The `Serper` web search tool was properly initialized and integrated with the specialist agents.
    -   The `NutritionTool` and `ExerciseTool` were implemented to leverage the web search tool, significantly improving the quality of health recommendations.

-   **API and Error Handling**:
    -   The API endpoint had leaky error handling, exposing internal tracebacks to the user.

-   **Architectural Enhancements**:
    -   Synchronous functions defined with `async` were corrected.
    -   The application was updated to handle long-running tasks asynchronously to prevent timeouts.

## Sample Outputs

The `outputs` directory contains sample outputs generated by the application, including:
-   Screenshots of the Chainlit interface in action.
-   A screencast demonstrating the application's workflow.


## How to Run

This project now uses a more robust architecture with a background worker queue to handle analysis tasks asynchronously.

### Prerequisites

-   Python 3.7+
-   Redis Server
-   An environment with the required packages installed.

### Installation

1.  **Clone the repository**:
    ```bash
    git clone https://github.com/VWO-Inc/VWO-Assignment.git
    cd VWO-Assignment/vwo-assignment
    ```

2.  **Install Python packages**:
    ```bash
    pip install -r requirements.txt
    ```

3.  **Set up your environment variables**. You'll need an API key for the language model. Create a `.env` file in the `vwo-assignment` directory:
    ```
    OPENAI_API_KEY="your-api-key"
    ```
    Or if you're using Gemini:
    ```
    GOOGLE_API_KEY="your-api-key"
    ```

4.  **Initialize the Database**:
    Run the following command from the `vwo-assignment` directory to create the `analysis_results.db` file.
    ```bash
    python database.py
    ```

### Running the Application

You need to run three components in separate terminals from the `vwo-assignment` directory.

1.  **Start the Redis Server**:
    Make sure your Redis server is running. If you installed it via a package manager like `apt` or `brew`, it might already be running as a service.
    ```bash
    redis-server
    ```

2.  **Start the Celery Worker**:
    ```bash
    celery -A worker.celery_app worker --loglevel=info
    ```

3.  **Start the FastAPI Server**:
    ```bash
    python main.py
    ```
    The API will be available at `http://localhost:8000`.

4.  **Start the Chainlit UI**:
    ```bash
    chainlit run app.py -w
    ```
    The chat interface will be available at `http://localhost:8001` (or the next available port).



